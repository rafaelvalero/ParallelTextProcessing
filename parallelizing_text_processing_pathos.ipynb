{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to process text in the most parallel possible way.\n",
    "\n",
    "\n",
    "\n",
    "References:\n",
    " + Related questions online:\n",
    "     + Parallization using sklearn and tfidfvectorizer: https://stackoverflow.com/questions/28396957/sklearn-tfidf-vectorizer-to-run-as-parallel-jobs   \n",
    "\n",
    " +  Really good answer to parallelize using dataframes in python: http://blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply/\n",
    "  To re-do it using joblib: https://joblib.readthedocs.io/en/latest/auto_examples/parallel_memmap.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some libraries\n",
    "#!pip install git+https://github.com/uqfoundation/pathos\n",
    "from  time import time\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pathos.multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 1.211s.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, I will have to change the scoring on my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Well i'm not sure about the story nad it did s...\n",
       "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
       "2  Although I realize that principle is not one o...\n",
       "3  Notwithstanding all the legitimate fuss about ...\n",
       "4  Well, I will have to change the scoring on my ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# I put the data in pandas dataframe because of convinience for\n",
    "# other cases I am working with\n",
    "data_pd = pd.DataFrame(dataset.data)\n",
    "data_pd.rename(columns = {0:'text'},inplace = True)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give some more drama let artificiallyt growth the database\n",
    "data_pd = pd.concat([data_pd,data_pd])\n",
    "data_pd = pd.concat([data_pd,data_pd])\n",
    "data_pd = pd.concat([data_pd,data_pd])\n",
    "data_pd = pd.concat([data_pd,data_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features\n",
      "done in 19.646s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features\n",
    "# THE FIT IS NOT EASY TO PARALLELIZE\n",
    "print(\"Extracting tf-idf features\")\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit(data_pd['text'])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming tf-idf features...\n",
      "done in 39.631s.\n"
     ]
    }
   ],
   "source": [
    "# To select the feature in not easy to parallelize but\n",
    "# after been done, you can parallelize the actual transformation,\n",
    "# this is, the vectorization of the process\n",
    "# Use tf-idf TRANSFORM.\n",
    "print(\"Transforming tf-idf features...\")\n",
    "tfidf = tfidf_vectorizer.transform(data_pd['text'])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "CPU times: user 635 ms, sys: 304 ms, total: 939 ms\n",
      "Wall time: 6.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# I mostly borry this code from http://blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply/\n",
    "#ValueError: Pool not running\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "#num_partitions = 5\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "num_partitions = num_cores-2 # I like to leave some cores for other\n",
    "#processes\n",
    "print(num_partitions)\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "def parallelize_dataframe(df, func):\n",
    "    #from pathos.multiprocessing import ProcessingPool as Pool\n",
    "    a = np.array_split(df, num_partitions)\n",
    "    del df\n",
    "    pool = Pool(num_cores)\n",
    "    #df = pd.concat(pool.map(func, [a,b,c,d,e]))\n",
    "    df = sp.vstack(pool.map(func, a), format='csr')\n",
    "    #pool.close() # For multiprocessing library\n",
    "    #pool.join() # For multiprocessing library\n",
    "    pool.terminate() # For pathos.multiprocessing library\n",
    "    pool.restart() # For pathos.multiprocessing library\n",
    "    return df\n",
    " \n",
    "def test_func(data):\n",
    "    #print(\"Process working on: \",data)\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(data[\"text\"])\n",
    "    #return pd.DataFrame(tfidf_matrix.toarray())\n",
    "    return tfidf_matrix\n",
    " \n",
    "#df = pd.DataFrame({'col': [0,1,2,3,4,5,6,7,8,9]})\n",
    "#df =  data_pd\n",
    "tfidf_parallel = parallelize_dataframe(data_pd, test_func)\n",
    "#print(tfidf_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035350.6785209675"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are really the same?\n",
    "# You could visualize them, here I am going to compare the sum of all their elements.\n",
    "tfidf_parallel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035350.6785209675"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
