{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelising text vectorisation transformations on csr matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse_matrix # for sparse matrix operations\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # the word vectoriser\n",
    "\n",
    "import time # for reporting time elapsed\n",
    "\n",
    "import random # for generating random text\n",
    "import string # for string operations\n",
    "\n",
    "from joblib import Parallel, delayed # the parallelisation library\n",
    "from multiprocessing import cpu_count # for finding the number of threads\n",
    "num_cores = cpu_count() # store the thread count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print elapsed time\n",
    "def elapsed_time():\n",
    "    print(\"Finished in %0.2fs.\" % (time.time() - t0),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n",
      "Finished in 0.62s. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Eldon Base for stackable storage shelf, platin...\n",
       "1    1.7 Cubic Foot Compact \"Cube\" Office Refrigera...\n",
       "2    Cardinal Slant-DÂ® Ring Binder, Heavy Gauge Vin...\n",
       "3    R380 Clay Rozendal 483 1198.97 195.99 3.99 Nun...\n",
       "4    Holmes HEPA Air Purifier Carlos Soltero 515 30...\n",
       "Name: Col0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "952112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Generating dataset...\")\n",
    "t0 = time.time()\n",
    "\n",
    "docs = pd.read_csv(r'.\\sample_data.csv').astype(str)\n",
    "for i in range(1,len(docs.columns)): # join all columns together\n",
    "    docs.iloc[:,0] = docs.iloc[:,0] + ' ' + docs.iloc[:,i]\n",
    "docs = docs['Col0']\n",
    "\n",
    "for i in range(4): # increase the size of the text to near 1 million\n",
    "    docs = pd.concat([docs, docs], axis=0, sort=False, copy=False)\n",
    "\n",
    "elapsed_time()\n",
    "display(docs.head(),docs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features...\n",
      "Finished in 18.11s. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf-idf features...\")\n",
    "\n",
    "t0 = time.time()\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word') # initialise word counter\n",
    "tfidf_vectorizer.fit(docs) # word counts\n",
    "\n",
    "elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un-parallelised transformation of given column...\n",
      "Finished in 18.00s. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Un-parallelised transformation of given column...\")\n",
    "\n",
    "t0 = time.time()\n",
    "tfidf = tfidf_vectorizer.transform(docs)\n",
    "\n",
    "elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformation using fitted vectoriser\n",
    "def tfidf_transform(split_array):\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(split_array)\n",
    "#     time.sleep(0.1)\n",
    "    return tfidf_matrix\n",
    "\n",
    "# Parellelisation\n",
    "def parallelise_vectorisation(vectorise_col, tfidf_transform=tfidf_transform):\n",
    "    split_array = np.array_split(vectorise_col, num_cores) # split column row-wise by number of cores\n",
    "    results = Parallel(n_jobs=num_cores, verbose=0, backend=\"threading\")(map(delayed(tfidf_transform), split_array)) # threading expecting given column broken in parts\n",
    "    tfidf_matrix = sparse_matrix.csr_matrix((0,results[0].shape[1]), dtype=np.uint8) # instantiate an empty csr matrix with 0 rows and the same number of columns as any of the split results\n",
    "    for i in range(len(results)): \n",
    "        tfidf_matrix = sparse_matrix.vstack([tfidf_matrix,results[i]], format='csr') # join the results together using sparse format, csr works best\n",
    "    return tfidf_matrix # return the joined matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelised execution using joblib...\n",
      "Finished in 17.38s. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Parallelised execution using joblib...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "tfidf_parallel = parallelise_vectorisation(docs)\n",
    "\n",
    "elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check using summation\n",
    "tfidf.sum() == tfidf_parallel.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Sources:\n",
    "    + Parallelisation using sklearn and tfidfvectorizer: https://stackoverflow.com/questions/28396957/sklearn-tfidf-vectorizer-to-run-as-parallel-jobs   \n",
    "    + Parallelise using dataframes in python: http://blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
